{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/syk-yaman/plantemoji/blob/master/Code/Colab/Plantemoji-LTSM.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "2695NZIOP5m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install influxdb-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H72ck1c32V1",
        "outputId": "54fec225-50ee-4807-f456-70f94cc28df6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kkjalB9g3WGh"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import influxdb_client\n",
        "from influxdb_client.client.write_api import SYNCHRONOUS\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import logging\n",
        "from scipy.signal import find_peaks\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bucket = \"\"\n",
        "org = \"\"\n",
        "token = \"\"\n",
        "# Store the URL of your InfluxDB instance\n",
        "url=\"\""
      ],
      "metadata": {
        "id": "qF3c8nNz3twP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = influxdb_client.InfluxDBClient(\n",
        "   url=url,\n",
        "   token=token,\n",
        "   org=org\n",
        ")"
      ],
      "metadata": {
        "id": "4q_4abir4pUM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_api = client.query_api()"
      ],
      "metadata": {
        "id": "ApuKaRVn40IN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'from(bucket: \"casa-mqtt-data\")\\\n",
        "  |> range(start: 2023-02-24T00:00:00.000000000Z, stop: 2023-03-05T23:59:59.941926044Z)\\\n",
        "  |> filter(fn: (r) => r[\"_field\"] == \"value\")\\\n",
        "  |> filter(fn: (r) => r[\"host\"] == \"30f2640405ed\")\\\n",
        "  |> filter(fn: (r) => r[\"plant-topics\"] == \"student/CASA0014/plant/ucfnmyr/plantemoji/airHumidity\")\\\n",
        " '"
      ],
      "metadata": {
        "id": "LEsGQ9YY4371"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = query_api.query(org=org, query=query)\n"
      ],
      "metadata": {
        "id": "7SGdwbEL5roV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for table in result:\n",
        "  for record in table.records:\n",
        "    results.append((record.get_time(), record.get_value()))\n",
        "\n"
      ],
      "metadata": {
        "id": "jRqZKQ8X5_xe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(results))\n",
        "array = np.array(results)\n",
        "df = pd.DataFrame(array[:, 1], columns=['humidity'])\n",
        "print(df)\n",
        "df.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "16CnkjsiOfWP",
        "outputId": "4fb0956a-615b-48ef-b0a9-b27746a9f58b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df)) # 401\n",
        "val_percent = 0.1 # 10 percent of data\n",
        "len(df)*val_percent\n",
        "val_point = np.round(len(df)*val_percent)\n",
        "val_index = int(len(df) - val_point)\n",
        "train = df.iloc[:val_index]\n",
        "val = df.iloc[val_index:]\n",
        "\n",
        "print(len(train))\n",
        "print(len(val))\n",
        "\n",
        "plt.plot(train)\n",
        "plt.plot(val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "jma7XOUEVDek",
        "outputId": "d9bba6af-741b-4881-aa99-eafa5929b200"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
        "scaler.fit(df)\n",
        "scaled_train = scaler.transform(train)\n",
        "scaled_val = scaler.transform(val)"
      ],
      "metadata": {
        "id": "B2mShbXx6MJc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 20\n",
        "batch_size = 4\n",
        "n_features = 1\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "generator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=batch_size)\n",
        "validation_generator = TimeseriesGenerator(scaled_val, scaled_val, length=length, batch_size=batch_size)\n",
        "\n",
        "lstm_model = Sequential()\n",
        "\n",
        "output_space = length # Same as number of time steps in the training window\n",
        "\n",
        "lstm_model.add(LSTM(output_space, input_shape=(length, n_features)))\n",
        "\n",
        "#lstm_model.add(LSTM(output_space, return_sequences=True, input_shape=(length,n_features)))\n",
        "#lstm_model.add(LSTM(output_space))\n",
        "\n",
        "lstm_model.add(Dense(1))\n",
        "\n",
        "lstm_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
        "lstm_model.fit(generator, epochs=2, validation_data=validation_generator, callbacks=[callback])"
      ],
      "metadata": {
        "id": "1lkxt3qWT7O0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745b44c0-7fc5-4f25-c5be-fdf299a24146"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = []\n",
        "\n",
        "first_eval_batch = scaled_train[-length:]\n",
        "\n",
        "current_batch = first_eval_batch.reshape(1, length,n_features)\n",
        "\n",
        "\n",
        "for i in range(len(val)):\n",
        "  current_pred = lstm_model.predict(current_batch)[0]\n",
        "\n",
        "  test_predictions.append(current_pred)\n",
        "\n",
        "  current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis = 1)\n",
        "\n",
        "true_predictions = scaler.inverse_transform(test_predictions)\n",
        "val['LSTM Predictions'] = true_predictions\n",
        "val.plot(figsize=(12,8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aRYo4kK9CI6",
        "outputId": "ed14ceea-7904-4b35-964a-0eaf3b59a106"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = []\n",
        "full_scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
        "scaled_full_data = full_scaler.fit_transform(df)\n",
        "first_eval_batch = scaled_full_data[-length:]\n",
        "\n",
        "current_batch = first_eval_batch.reshape(1, length, n_features)\n",
        "\n",
        "\n",
        "for i in range(40):\n",
        "  current_pred = lstm_model.predict(current_batch)[0]\n",
        "\n",
        "  forecast.append(current_pred)\n",
        "\n",
        "  current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis = 1)"
      ],
      "metadata": {
        "id": "m1hb2OHH9Ej_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = full_scaler.inverse_transform(forecast)\n",
        "\n",
        "forecast_index = np.arange(401, 441, step=1)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(df.index, df['light'])\n",
        "plt.plot(forecast_index, forecast)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4PtK-ZSA9JHa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}